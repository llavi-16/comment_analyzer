{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeb580e2-7a1c-4b77-92da-06e394aea89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# Import functions for data preprocessing & data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdbb85c4-cd15-4381-9894-e73e9ebc3f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedTime</th>\n",
       "      <th>SimpleText</th>\n",
       "      <th>votes</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>We are grateful to Ari and her crew for select...</td>\n",
       "      <td>465</td>\n",
       "      <td>@HalisRioe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Here for this! X</td>\n",
       "      <td>1</td>\n",
       "      <td>@naomisegal5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>HERE FOR EVAN!!</td>\n",
       "      <td>4</td>\n",
       "      <td>@Ireallydintknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Who is Evan? Thanks.</td>\n",
       "      <td>0</td>\n",
       "      <td>@SofiNme365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Ari inspires me.. My parents said if i get 3K ...</td>\n",
       "      <td>1</td>\n",
       "      <td>@PoorWorldwithoutgod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Robyn Dancing on my own ðŸ¤—</td>\n",
       "      <td>0</td>\n",
       "      <td>@user-jv8il3br9e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Tu mÃºsica es lo mejor que me ha pasado</td>\n",
       "      <td>0</td>\n",
       "      <td>@irammorales1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Evan Peters ðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
       "      <td>0</td>\n",
       "      <td>@adamautumn2329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>He is evan Peters ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
       "      <td>0</td>\n",
       "      <td>@biruth30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Eu to chocada mulheeerðŸ˜®</td>\n",
       "      <td>0</td>\n",
       "      <td>@eubeatricee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    publishedTime                                         SimpleText  votes  \\\n",
       "0      10-03-2024  We are grateful to Ari and her crew for select...    465   \n",
       "1      10-03-2024                                   Here for this! X      1   \n",
       "2      10-03-2024                                    HERE FOR EVAN!!      4   \n",
       "3      10-03-2024                               Who is Evan? Thanks.      0   \n",
       "4      10-03-2024  Ari inspires me.. My parents said if i get 3K ...      1   \n",
       "..            ...                                                ...    ...   \n",
       "508    10-03-2024                          Robyn Dancing on my own ðŸ¤—      0   \n",
       "509    10-03-2024             Tu mÃºsica es lo mejor que me ha pasado      0   \n",
       "510    10-03-2024                                    Evan Peters ðŸ˜­ðŸ˜­ðŸ˜­      0   \n",
       "511    10-03-2024                           He is evan Peters ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­      0   \n",
       "512    10-03-2024                            Eu to chocada mulheeerðŸ˜®      0   \n",
       "\n",
       "                   author  \n",
       "0              @HalisRioe  \n",
       "1         @naomisegal5115  \n",
       "2        @Ireallydintknow  \n",
       "3             @SofiNme365  \n",
       "4    @PoorWorldwithoutgod  \n",
       "..                    ...  \n",
       "508      @user-jv8il3br9e  \n",
       "509      @irammorales1354  \n",
       "510       @adamautumn2329  \n",
       "511             @biruth30  \n",
       "512          @eubeatricee  \n",
       "\n",
       "[513 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Downloads/Ariana Grande - we cant be friends (wait for your love) (official music video) 3-10-2024.csv')\n",
    "data.columns\n",
    "data1=data.drop(['isReply','isHearted','isPinned','isPaid','paidAmount','isSponsor','sponsorshipMonths'],axis=1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab7ab87-62f8-4fae-9b27-e095215f0b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['publishedTime', 'SimpleText', 'votes', 'author', 'isReply',\n",
      "       'isHearted', 'isPinned', 'isPaid', 'paidAmount', 'isSponsor',\n",
      "       'sponsorshipMonths'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a10245c-ffac-435d-a202-a13aad660d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedTime</th>\n",
       "      <th>SimpleText</th>\n",
       "      <th>votes</th>\n",
       "      <th>author</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>We are grateful to Ari and her crew for select...</td>\n",
       "      <td>465</td>\n",
       "      <td>@HalisRioe</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Here for this! X</td>\n",
       "      <td>1</td>\n",
       "      <td>@naomisegal5115</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>HERE FOR EVAN!!</td>\n",
       "      <td>4</td>\n",
       "      <td>@Ireallydintknow</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Who is Evan? Thanks.</td>\n",
       "      <td>0</td>\n",
       "      <td>@SofiNme365</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Ari inspires me.. My parents said if i get 3K ...</td>\n",
       "      <td>1</td>\n",
       "      <td>@PoorWorldwithoutgod</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publishedTime                                         SimpleText  votes  \\\n",
       "0    10-03-2024  We are grateful to Ari and her crew for select...    465   \n",
       "1    10-03-2024                                   Here for this! X      1   \n",
       "2    10-03-2024                                    HERE FOR EVAN!!      4   \n",
       "3    10-03-2024                               Who is Evan? Thanks.      0   \n",
       "4    10-03-2024  Ari inspires me.. My parents said if i get 3K ...      1   \n",
       "\n",
       "                 author  Positive  Negative  Neutral  Compound Sentiment  \n",
       "0            @HalisRioe     0.244       0.0    0.756    0.6705  Positive  \n",
       "1       @naomisegal5115     0.000       0.0    1.000    0.0000   Neutral  \n",
       "2      @Ireallydintknow     0.000       0.0    1.000    0.0000   Neutral  \n",
       "3           @SofiNme365     0.492       0.0    0.508    0.4404  Positive  \n",
       "4  @PoorWorldwithoutgod     0.206       0.0    0.794    0.6908  Positive  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data1[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data1[\"SimpleText\"]]\n",
    "data1[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data1[\"SimpleText\"]]\n",
    "data1[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data1[\"SimpleText\"]]\n",
    "data1['Compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data1[\"SimpleText\"]]\n",
    "score = data1[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i >= 0.05 :\n",
    "        sentiment.append('Positive')\n",
    "    elif i <= -0.05 :\n",
    "        sentiment.append('Negative')\n",
    "    else:\n",
    "        sentiment.append('Neutral')\n",
    "data1[\"Sentiment\"] = sentiment\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea1b1b7f-bf49-4d93-8488-dca961deffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedTime</th>\n",
       "      <th>SimpleText</th>\n",
       "      <th>votes</th>\n",
       "      <th>author</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>We are grateful to Ari and her crew for select...</td>\n",
       "      <td>465</td>\n",
       "      <td>@HalisRioe</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Here for this! X</td>\n",
       "      <td>1</td>\n",
       "      <td>@naomisegal5115</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>HERE FOR EVAN!!</td>\n",
       "      <td>4</td>\n",
       "      <td>@Ireallydintknow</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Who is Evan? Thanks.</td>\n",
       "      <td>0</td>\n",
       "      <td>@SofiNme365</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-03-2024</td>\n",
       "      <td>Ari inspires me.. My parents said if i get 3K ...</td>\n",
       "      <td>1</td>\n",
       "      <td>@PoorWorldwithoutgod</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publishedTime                                         SimpleText  votes  \\\n",
       "0    10-03-2024  We are grateful to Ari and her crew for select...    465   \n",
       "1    10-03-2024                                   Here for this! X      1   \n",
       "2    10-03-2024                                    HERE FOR EVAN!!      4   \n",
       "3    10-03-2024                               Who is Evan? Thanks.      0   \n",
       "4    10-03-2024  Ari inspires me.. My parents said if i get 3K ...      1   \n",
       "\n",
       "                 author Sentiment  \n",
       "0            @HalisRioe  Positive  \n",
       "1       @naomisegal5115   Neutral  \n",
       "2      @Ireallydintknow   Neutral  \n",
       "3           @SofiNme365  Positive  \n",
       "4  @PoorWorldwithoutgod  Positive  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "185ce63c-5a40-48d8-bd72-a6c0a98d4fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96f1e640-817a-455e-989d-0471c7d0d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer() \n",
    "snowball_stemer = SnowballStemmer(language=\"english\")\n",
    "lzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f53dda1-70d5-49e3-a325-fef0bc1ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def text_processing(text):   \n",
    "    # convert text into lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove new line characters in text\n",
    "    text = re.sub(r'\\n',' ', text)\n",
    "    \n",
    "    # remove punctuations from text\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n",
    "    \n",
    "    # remove references and hashtags from text\n",
    "    text = re.sub(\"^a-zA-Z0-9$,.\", \"\", text)\n",
    "    \n",
    "    # remove multiple spaces from text\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # remove special characters from text\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    \n",
    "    # stemming using porter stemmer from nltk package - msh a7sn 7aga - momken: lancaster, snowball\n",
    "    # text=' '.join([porter_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([lancaster_stemmer.stem(word) for word in word_tokenize(text)])\n",
    "    # text=' '.join([snowball_stemer.stem(word) for word in word_tokenize(text)])\n",
    "    \n",
    "    # lemmatizer using WordNetLemmatizer from nltk package\n",
    "    text=' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46948d9d-7882-4d74-a5e3-a8ce664f1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93a79bb6-bca5-44b5-9354-6a64f2e81514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grateful ari crew selecting evan enabling foll...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evan thanks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari inspires parent said get 3k like vid theyd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment\n",
       "0  grateful ari crew selecting evan enabling foll...          2\n",
       "1                                                  x          1\n",
       "2                                               evan          1\n",
       "3                                        evan thanks          2\n",
       "4  ari inspires parent said get 3k like vid theyd...          2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy = data2.copy()\n",
    "data_copy.SimpleText = data_copy.SimpleText.apply(lambda text: text_processing(text))\n",
    "     \n",
    "\n",
    "le = LabelEncoder()\n",
    "data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])\n",
    "     \n",
    "\n",
    "processed_data = {\n",
    "    'Sentence':data_copy.SimpleText,\n",
    "    'Sentiment':data_copy['Sentiment']\n",
    "}\n",
    "\n",
    "processed_data = pd.DataFrame(processed_data)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4747b663-0f18-4973-9e4e-affe372134d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    246\n",
       "2    195\n",
       "0     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3683f83f-2a3f-441a-b694-1e62ab727774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "0    205\n",
       "1    205\n",
       "2    195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_neutral = processed_data[(processed_data['Sentiment']==1)] \n",
    "df_negative = processed_data[(processed_data['Sentiment']==0)]\n",
    "df_positive = processed_data[(processed_data['Sentiment']==2)]\n",
    "\n",
    "# upsample minority classes\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "df_neutral_upsampled = resample(df_neutral, \n",
    "                                 replace=True,    \n",
    "                                 n_samples= 205, \n",
    "                                 random_state=42)  \n",
    "\n",
    "\n",
    "# Concatenate the upsampled dataframes with the neutral dataframe\n",
    "final_data = pd.concat([df_negative_upsampled,df_neutral_upsampled,df_positive])\n",
    "     \n",
    "\n",
    "final_data['Sentiment'].value_counts()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9c31d82-a5b7-4878-9941-2339649e0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hurt',\n",
       " 'recordÃ³ eterno resplandor de una mente sin recuerdos',\n",
       " 'first sentence made cry',\n",
       " 'ari absolutely broke heart one dont know would ever recover incredibly sad beautiful time',\n",
       " 'el resumen perfecto de eterno resplandor de una mente sin recuerdos con mÃºsica de ariana grande']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = []\n",
    "for sentence in final_data['Sentence']:\n",
    "    corpus.append(sentence)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a75e1cee-2482-4d8f-b374-32817ef508b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = final_data.iloc[:, -1].values\n",
    "     \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "     \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "     \n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "928b612f-bdd3-4f21-99f7-79f1ca38c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bf28871-fc85-47a1-9a2e-643e3c8a5c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  1,  0],\n",
       "       [ 5, 52,  7],\n",
       "       [16,  6, 40]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "363016bd-b97c-40c6-b6ad-686e3aeab4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "nb_score = accuracy_score(y_test, y_pred)\n",
    "nb_score\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee176b-471c-40f0-8f9c-f5db57c31cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
